{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing dependencies\n",
    "import csv\n",
    "import cv2\n",
    "import h5py\n",
    "import itertools\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import skimage\n",
    "import warnings\n",
    "import zlib\n",
    "\n",
    "from glob import glob\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from keras import backend as K\n",
    "from keras import models, layers, optimizers\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten, Conv2D, MaxPool2D, Lambda, MaxPooling2D, AveragePooling2D, BatchNormalization\n",
    "from keras.models import Model, Sequential, model_from_json\n",
    "from keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta, RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from skimage.transform import resize\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, learning_curve, KFold, cross_val_score, StratifiedKFold\n",
    "from sklearn.utils import class_weight\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables\n",
    "#Directories\n",
    "dir_dataset = \"../DataSet/\"\n",
    "dir_dataset_train = dir_dataset + \"train/\"\n",
    "dir_dataset_test  = dir_dataset + \"test/\"\n",
    "dir_transferlearning = \"../TransferLearning/\"\n",
    "\n",
    "#Labels\n",
    "normal_label    = 0\n",
    "pneumonia_label = 1\n",
    "unknown_label   = 2\n",
    "\n",
    "#Dataset\n",
    "name_dataset = \"dataset.h5\"\n",
    "exists_dataset = True\n",
    "\n",
    "#Directories Transfer learning\n",
    "pretrained_label_VGG16 = 'VGG16'\n",
    "pretrained_label_InceptionV3 = 'InceptionV3'\n",
    "\n",
    "dir_transferlearning_vgg16 = dir_transferlearning +  \"Vgg16.h5\"\n",
    "dir_transferlearning_inception = dir_transferlearning +  \"InceptionV3.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining hyperparameters\n",
    "height_img          = 150\n",
    "width_img           = 150\n",
    "channel_img         = 3\n",
    "max_epoch_vgg16     = 100\n",
    "max_epoch_inception = 100\n",
    "number_classes      = 2\n",
    "optimizer           = keras.optimizers.RMSprop(lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining map characters and transferLearning\n",
    "map_characters = {normal_label: 'No Pneumonia',\n",
    "                  pneumonia_label: 'Yes Pneumonia'}\n",
    "\n",
    "pretrained_model_VGG16 = VGG16(weights = dir_transferlearning_vgg16,\n",
    "                               include_top=False,\n",
    "                               input_shape=(height_img, width_img, channel_img))\n",
    "\n",
    "pretrained_model_InceptionV3 = InceptionV3(weights = dir_transferlearning_inception,\n",
    "                                           include_top=False,\n",
    "                                           input_shape=(height_img, width_img, channel_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and define mehotd resizing load image\n",
    "def get_dataset_resizing(folder):\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    for folderName in os.listdir(folder):\n",
    "        if not folderName.startswith('.'):\n",
    "            \n",
    "            if folderName in ['NORMAL']:\n",
    "                label = normal_label\n",
    "            elif folderName in ['PNEUMONIA']:\n",
    "                label = pneumonia_label\n",
    "            else:\n",
    "                label = unknown_label\n",
    "                \n",
    "            for image_filename in tqdm(os.listdir(folder + folderName)):\n",
    "                img_file = cv2.imread(folder + folderName + '/' + image_filename)\n",
    "                \n",
    "                if img_file is not None:\n",
    "                    img_file = skimage.transform.resize(img_file, (height_img, width_img, channel_img))                \n",
    "                    img_arr = np.asarray(img_file)\n",
    "                    x.append(img_arr)\n",
    "                    y.append(label)\n",
    "                    \n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    \n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create memory dataset\n",
    "if not exists_dataset:\n",
    "    x_train, y_train = get_dataset_resizing(dir_dataset_train)\n",
    "    x_test,  y_test  = get_dataset_resizing(dir_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dataset in computer or load dataset from computer\n",
    "if not exists_dataset:\n",
    "    hf = h5py.File(name_dataset, 'w')\n",
    "    hf.create_dataset('x_train', data=x_train)\n",
    "    hf.create_dataset('y_train', data=y_train)\n",
    "    hf.create_dataset('x_test', data=x_test)\n",
    "    hf.create_dataset('y_test', data=y_test)\n",
    "    hf.close()\n",
    "else:\n",
    "    with h5py.File(name_dataset,'r') as hf:\n",
    "        x_train = hf['x_train'][:]\n",
    "        y_train = hf['y_train'][:]\n",
    "        x_test  = hf['x_test'][:]\n",
    "        y_test  = hf['y_test'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converts the dataset to binary array\n",
    "y_train_hot = to_categorical(y_train, num_classes = number_classes)\n",
    "y_test_hot  = to_categorical(y_test, num_classes = number_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining metric and presentation of the obtained results\n",
    "class MetricsCheckpoint(Callback):    \n",
    "    def __init__(self, savepath):\n",
    "        super(MetricsCheckpoint, self).__init__()\n",
    "        self.savepath = savepath\n",
    "        self.history = {}\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        np.save(self.savepath, self.history)\n",
    "\n",
    "def plotKerasLearningCurve():\n",
    "    plt.figure(figsize=(10,5))\n",
    "    metrics = np.load('logs.npy')[()]\n",
    "    filt = ['acc']\n",
    "    \n",
    "    for k in filter(lambda x : np.any([kk in x for kk in filt]), metrics.keys()):\n",
    "        l = np.array(metrics[k])\n",
    "        plt.plot(l, c= 'r' if 'val' not in k else 'b', label='val' if 'val' in k else 'train')\n",
    "        x = np.argmin(l) if 'loss' in k else np.argmax(l)\n",
    "        y = l[x]\n",
    "        plt.scatter(x,y, lw=0, alpha=0.25, s=100, c='r' if 'val' not in k else 'b')\n",
    "        plt.text(x, y, '{} = {:.10f}'.format(x,y), size='15', color= 'r' if 'val' not in k else 'b')   \n",
    "        \n",
    "    plt.legend(loc=4)\n",
    "    plt.axis([0, None, None, None]);\n",
    "    plt.grid()\n",
    "    plt.xlabel('Number of epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize = (5,5))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def plot_learning_curve(history):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig('./accuracy_curve.png')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "    plt.savefig('./loss_curve.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining network architecture\n",
    "def pretrainedNetwork(xtrain, ytrain, xtest, ytest, i_pretrained_model, pretrained_label,\n",
    "                      i_pretrained_weights, i_class_weight, i_num_classes,\n",
    "                      i_max_epochs, i_optimizer, i_labels):\n",
    "    \n",
    "    if pretrained_label in pretrained_label_VGG16:\n",
    "        base_model  = pretrained_model_VGG16\n",
    "    elif pretrained_label in pretrained_label_InceptionV3:        \n",
    "        base_model  = pretrained_model_InceptionV3    \n",
    "    else:\n",
    "        base_model  = pretrained_model_VGG16       \n",
    "        \n",
    "    x           = base_model.output\n",
    "    x           = Flatten()(x)\n",
    "    predictions = Dense(i_num_classes, activation='softmax')(x)\n",
    "    model       = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False        \n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=i_optimizer, \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    callbacks_list = [keras.callbacks.EarlyStopping(monitor='val_acc', patience=3, verbose=1)]\n",
    "    model.summary()\n",
    "    \n",
    "    history = model.fit(xtrain, ytrain, epochs=i_max_epochs, class_weight=i_class_weight,\n",
    "                        validation_data=(xtest, ytest), verbose=1,\n",
    "                        callbacks = [MetricsCheckpoint('logs')])\n",
    "    \n",
    "    model.save_weights('DeepLearningPneumonia.h5')\n",
    "    \n",
    "    score = model.evaluate(xtest, ytest, verbose=0)\n",
    "    print('\\nKeras CNN - accuracy:', score[1], '\\n')\n",
    "    \n",
    "    y_pred = model.predict(xtest)\n",
    "    print('\\n', sklearn.metrics.classification_report(np.where(ytest > 0)[1],\n",
    "                                                      np.argmax(y_pred, axis=1),\n",
    "                                                      target_names=list(i_labels.values())), sep='') \n",
    "    \n",
    "    Y_pred_classes = np.argmax(y_pred, axis = 1) \n",
    "    Y_true = np.argmax(ytest, axis = 1) \n",
    "    confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "    plotKerasLearningCurve()\n",
    "    plt.show()\n",
    "    plot_learning_curve(history)\n",
    "    plt.show()\n",
    "    plot_confusion_matrix(confusion_mtx, classes = list(i_labels.values()))\n",
    "    plt.show()\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial weights\n",
    "x_train_shape = x_train.shape[1]*x_train.shape[2]*x_train.shape[3]\n",
    "x_test_shape  = x_test.shape[1]*x_test.shape[2]*x_test.shape[3]\n",
    "x_train_flat  = x_train.reshape(x_train.shape[0], x_train_shape)\n",
    "x_test_flat   = x_test.reshape(x_test.shape[0], x_test_shape)\n",
    "\n",
    "yy_train = y_train\n",
    "yy_test  = y_test\n",
    "ros      = RandomUnderSampler(ratio='auto')\n",
    "\n",
    "x_train_ros, y_train_ros = ros.fit_sample(x_train_flat, yy_train)\n",
    "x_test_ros, y_test_ros   = ros.fit_sample(x_test_flat, yy_test)\n",
    "\n",
    "y_train_ros_hot = to_categorical(y_train_ros, num_classes = number_classes)\n",
    "y_test_ros_hot = to_categorical(y_test_ros, num_classes = number_classes)\n",
    "\n",
    "for i in range(len(x_train_ros)):\n",
    "    height, width, channels = height_img, width_img, channel_img\n",
    "    x_train_ros_reshaped = x_train_ros.reshape(len(x_train_ros), height, width, channels)\n",
    "    \n",
    "for i in range(len(x_test_ros)):\n",
    "    height, width, channels = height_img, width_img, channel_img\n",
    "    x_test_ros_reshaped = x_test_ros.reshape(len(x_test_ros), height,width, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weight balancing\n",
    "class_weight_y = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "print(\"Class Weights: \", class_weight_y)\n",
    "\n",
    "class_weight_yy = class_weight.compute_class_weight('balanced', np.unique(yy_train), yy_train)\n",
    "print(\"Old Class Weights: \", class_weight_yy)\n",
    "\n",
    "class_weight_ros = class_weight.compute_class_weight('balanced', np.unique(y_train_ros), y_train_ros)\n",
    "print(\"New Class Weights: \", class_weight_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#training network VGG16\n",
    "pretrainedNetwork(x_train_ros_reshaped, y_train_ros_hot, x_test_ros_reshaped, y_test_ros_hot,\n",
    "                  pretrained_model_VGG16, pretrained_label_VGG16, dir_transferlearning_vgg16,\n",
    "                  class_weight_ros, number_classes, max_epoch_vgg16, optimizer, map_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#raining network InceptionV3\n",
    "\n",
    "#Não obitivemos bons resultados com a InceptionV3\n",
    "\n",
    "#retrainedNetwork(x_train_ros_reshaped, y_train_ros_hot, x_test_ros_reshaped, y_test_ros_hot,\n",
    "                  #retrained_model_InceptionV3, pretrained_label_InceptionV3, dir_transferlearning_inception,\n",
    "                  #lass_weight_ros, number_classes, max_epoch_inception, optimizer, map_characters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
